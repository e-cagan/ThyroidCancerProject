{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26aed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login huggingface for access of dataset\n",
    "from huggingface_hub import login\n",
    "\n",
    "HF_TOKEN = \"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\"\n",
    "login(token=HF_TOKEN, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a0669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading huggingface data\n",
    "def load_hf_data():\n",
    "    # Load dataset\n",
    "    dataset = load_dataset(\"FangDai/Thyroid_Ultrasound_Images\", token=HF_TOKEN)\n",
    "    \n",
    "    # Split train and validation data\n",
    "    train_data = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "    \n",
    "    # Function for preprocessing images\n",
    "    def preprocess(batch):\n",
    "        images = [img.convert(\"RGB\").resize((224, 224)) for img in batch[\"image\"]]\n",
    "        return {\n",
    "            \"image\": [np.array(img, dtype=np.float32)/255.0 for img in images],\n",
    "            \"label\": batch[\"label\"]\n",
    "        }\n",
    "    \n",
    "    # Applying preprocessing\n",
    "    train_dataset = train_data[\"train\"].map(preprocess, batched=True, batch_size=32)\n",
    "    val_dataset = train_data[\"test\"].map(preprocess, batched=True, batch_size=32)\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "train_data, val_data = load_hf_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea5e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for converting huggingface dataset to tensorflow formatted dataset\n",
    "def to_tf_dataset(hf_dataset):\n",
    "    images = np.stack(hf_dataset[\"image\"])\n",
    "    labels = np.array(hf_dataset[\"label\"])\n",
    "    return tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "train_tf = to_tf_dataset(train_data).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_tf = to_tf_dataset(val_data).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab87a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = tf.keras.Sequential([\n",
    "    # Input layer\n",
    "    tf.keras.layers.Input(shape=(224, 224, 3)),\n",
    "    \n",
    "    # Convolutional layer 1\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    # Convolutional layer 2\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    # Convolutional layer 3\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    \n",
    "    # Output layer\n",
    "    tf.keras.layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d323b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, verbose=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"thyroid_model.keras\", save_best_only=True, verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.3, patience=3, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_tf,\n",
    "    validation_data=val_tf,\n",
    "    epochs=125,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e04d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "y_pred = np.argmax(model.predict(val_tf), axis=1)\n",
    "y_true = np.concatenate([y for x, y in val_tf], axis=0)\n",
    "loss, acc = model.evaluate(val_tf)\n",
    "\n",
    "print(f\"\\nTest Accuracy: {acc:.4f} | Test Loss: {loss:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"FTC\", \"MTC\", \"PTC\"]))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
